# lstm_pytorch_trainer.py

import os
import torch
import numpy as np
from torch import nn
from torch.utils.data import DataLoader, TensorDataset

from utils.bybit_api import get_bybit_historical_data
from utils.preprocess import preprocess_lstm_data
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from models.lstm_model import LSTMRegressor  # âœ… ì™¸ë¶€ ëª¨ë¸ íŒŒì¼ì—ì„œ import

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
SEQ_LEN = 60
BATCH_SIZE = 32
EPOCHS = 30
LR = 0.001

def train_and_save_model(interval_name, bybit_interval):
    print(f"\nğŸ“ˆ [{interval_name}] ë°ì´í„°ë¡œ í•™ìŠµ ì‹œì‘")

    # 1. ë°ì´í„° ìˆ˜ì§‘
    df = get_bybit_historical_data(interval=bybit_interval, limit=1000)
    if df is None or df.empty:
        print(f"âŒ [{interval_name}] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        return

    # 2. ì „ì²˜ë¦¬
    X_train, y_train, X_test, y_test, scaler = preprocess_lstm_data(df, sequence_length=SEQ_LEN)

    # 3. Tensor ë³€í™˜
    X_train = torch.tensor(X_train, dtype=torch.float32)
    y_train = torch.tensor(y_train, dtype=torch.float32)
    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)

    # 4. ëª¨ë¸ ì •ì˜
    model = LSTMRegressor()
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    # 5. í•™ìŠµ
    model.train()
    for epoch in range(EPOCHS):
        total_loss = 0
        for batch_X, batch_y in train_loader:
            optimizer.zero_grad()
            output = model(batch_X)
            loss = criterion(output, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"[{interval_name}] Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f}")

    # 6. ëª¨ë¸ ì €ì¥
    os.makedirs("models", exist_ok=True)
    model_path = f"models/lstm_model_{interval_name}.pt"
    torch.save(model.state_dict(), model_path)
    print(f"âœ… [{interval_name}] ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ {model_path}")

    # 7. ì •í™•ë„ í‰ê°€
    model.eval()
    with torch.no_grad():
        y_pred = model(torch.tensor(X_test, dtype=torch.float32)).numpy()

    y_pred_real = scaler.inverse_transform(y_pred)
    y_test_real = scaler.inverse_transform(y_test)

    mae = mean_absolute_error(y_test_real, y_pred_real)
    rmse = mean_squared_error(y_test_real, y_pred_real, squared=False)
    r2 = r2_score(y_test_real, y_pred_real)

    print(f"\nğŸ“Š [{interval_name}] ì •í™•ë„ í‰ê°€ ê²°ê³¼")
    print(f"ğŸ“‰ MAE: {mae:.2f}")
    print(f"ğŸ“‰ RMSE: {rmse:.2f}")
    print(f"ğŸ“ˆ RÂ² Score: {r2:.4f}")

# ğŸ”¥ ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":
    print("ğŸ”¥ FILE EXECUTED\n")

    INTERVALS = {
        '5m': '5',
        '15m': '15',
        '1h': '60',
        '4h': '240'
    }

    for name, bybit_code in INTERVALS.items():
        train_and_save_model(name, bybit_code)
